{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_bot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uStWMtd6Lfen",
        "colab_type": "code",
        "outputId": "479b657c-a2d6-475d-fe36-48d38922154d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w12NbCqw8qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/gdrive/My \\Drive\n",
        "!mkdir spyfall\n",
        "%cd spyfall\n",
        "!git clone https://github.com/EdGartner/spyfall-bot.git\n",
        "!mkdir gpt2\n",
        "%cd gpt2\n",
        "!git clone https://github.com/openai/gpt-2.git\n",
        "%cd /content/gdrive/My \\Drive/spyfall\n",
        "!mv sample.py gpt-2/src # bc there was an issue in gpt-2 sample.py for me"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYaF_A-9EMGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/gdrive/My \\Drive/spyfall/gpt2/\n",
        "!pip install -r requirements.txt\n",
        "# will require restart"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGSkJ421tFSW",
        "colab_type": "code",
        "outputId": "46735d5b-e2b3-4752-87f1-5a120c73024e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import json\n",
        "from importlib import reload \n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5IhkNYMETNR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f6c644c0-824a-41f2-c75e-4f7dd0b84708"
      },
      "source": [
        "%cd /content/gdrive/My \\Drive/spyfall/gpt2\n",
        "# !python download_model.py 355M\n",
        "!python download_model.py 774M\n",
        "# !python download_model.py 1558M"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/spyfall/gpt2\n",
            "Fetching checkpoint: 1.00kit [00:00, 729kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 35.4Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 579kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 3.10Git [01:17, 39.9Mit/s]                                 \n",
            "Fetching model.ckpt.index: 16.0kit [00:00, 8.82Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 1.38Mit [00:00, 41.1Mit/s]                                                \n",
            "Fetching vocab.bpe: 457kit [00:00, 30.2Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJn8BqIji8QZ",
        "colab_type": "code",
        "outputId": "197b1a20-3b3b-4f71-9bf1-8a76408b51a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/gdrive/My \\Drive/spyfall\n",
        "import spyfall_bot"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/spyfall\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkY1dloB5wvs",
        "colab_type": "code",
        "outputId": "093343a2-f3fc-473e-c59a-6285bb1f881b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prompts_text = ['Halfway through through the plane ride, the passengers began to feel restless.', \n",
        "                'It may have seemed like an ordinary morning at the local bank.',\n",
        "                'The sun shone brightly, and the beach was packed with visitors.',\n",
        "                'The lights dimmed, the curtains opened, and the audiance fell silent as the Broadway show began.']\n",
        "spyfall_bot = reload(spyfall_bot)\n",
        "bot = spyfall_bot.Bot(prompts_text, prompt_index=2, players=3, position=0, model_name='355M')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from gpt2/models/355M/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72dKy0dtPcWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transcript = ['Most people sit for hours in their chairs, exemplifying sedentary American culture.',\n",
        "              'Some people go swimming, though.',\n",
        "              'The waves are quite calm.',\n",
        "              'There is stand selling icecream.',\n",
        "              'Naturally, it is quite overpriced.',\n",
        "              'Seagulls wait eagerly for someone to drop their icecream.']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzoOYsRejMmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transcript2 = ['This should be ambiguous.',\n",
        "                'We ate supper early.',\n",
        "               'Then we went to the movies.',\n",
        "               'A few of us wanted to watch some garbage superhero movie.']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRMrTlqID20q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transcript3 = ['Everyone has stopped pretending to sleep.',\n",
        "               'A few people scroll through the few movie options.',\n",
        "               'It seems like everyone wants a stretch break.',\n",
        "               'The line for the bathroom has become quite long.']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj_5VqGdi0rG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb4fd747-4628-4f79-c2eb-594f67f1ae18"
      },
      "source": [
        "out = bot.generate(transcript)\n",
        "print(out)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " The sun is shining, and the beach is packed with people.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kNBDwzMB8mm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "ff511a5d-aa83-4c4f-8d5d-953ecbbca637"
      },
      "source": [
        "for i in range(1, len(transcript) + 1):\n",
        "    print(bot.guess(transcript[:i], confidence=0.75))\n",
        "    print(bot.saved)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "[-70.28787, -69.05453, -64.139984, -67.3635]\n",
            "2\n",
            "[-84.52867, -80.50754, -78.314255, -81.190346]\n",
            "2\n",
            "[-89.47648, -84.30553, -82.561455, -85.9196]\n",
            "2\n",
            "[-84.080376, -79.1309, -77.38501, -80.99927]\n",
            "2\n",
            "[-82.35436, -78.308014, -76.565544, -79.88332]\n",
            "False\n",
            "[-77.99781, -74.44355, -73.53957, -75.68668]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y23GtngmdCDf",
        "colab_type": "code",
        "outputId": "678c748c-844c-46ff-ade7-2c48611a6032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "for i in range(1, len(transcript2) + 1):\n",
        "    print(bot.guess(transcript2[:i], confidence=0.75))\n",
        "    print(bot.saved)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "[-82.05974, -77.631584, -74.31296, -69.43819]\n",
            "False\n",
            "[-93.83028, -85.08766, -85.97264, -88.23751]\n",
            "False\n",
            "[-92.809265, -84.76239, -85.43151, -86.72706]\n",
            "False\n",
            "[-85.768845, -79.54432, -78.95854, -82.483215]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6A8JYDJEmCf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f07b16ef-73b0-4eb9-c688-876d3c900346"
      },
      "source": [
        "for i in range(1, len(transcript3) + 1):\n",
        "    print(bot.guess(transcript3[:i], confidence=0.75))\n",
        "    print(bot.saved)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "[-108.23934, -97.671104, -107.1133, -103.78315]\n",
            "1\n",
            "[-98.30375, -89.46518, -94.67919, -94.25454]\n",
            "1\n",
            "[-93.318275, -85.93102, -88.06909, -89.20222]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDyY66bWKz8k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3428276a-3842-49a6-8777-eb9de720392e"
      },
      "source": [
        "print(bot.accuse(transcript))\n",
        "print(bot.saved)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "[1112.9725129255396, 7.487871329073559, 0.9445569029933457]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_3fLo20V_OP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bot.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}